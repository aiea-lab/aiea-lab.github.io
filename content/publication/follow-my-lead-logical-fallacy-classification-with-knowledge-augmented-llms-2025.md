+++
title = "Follow My Lead: Logical Fallacy Classification with Knowledge-Augmented LLMs"
publication = "arXiv preprint arXiv:2510.09970"
journal = "arXiv preprint arXiv:2510.09970"
year = "2025"
date = "2025-10-11"
abstract = "Large Language Models (LLMs) suffer from critical reasoning gaps, including a tendency to hallucinate and poor accuracy in classifying logical fallacies. This limitation stems from their default System 1 processing, which is fast and intuitive, whereas reliable reasoning requires the deliberate, effortful System 2 approach (Kahneman, 2011; Li et al., 2025). Since full System 2 training is often prohibitively expensive, we explore a low-cost, instruction-based intervention to bridge this gap. Our methodology introduces a novel stepwise instruction dataset that decomposes fallacy classification into a series of atomic procedural steps (simple binary questions). We further augment this with a final verification step where models consult a relational knowledge graph of related fallacies. This procedural, rule-based intervention yields a significant improvement in LLM logical fallacy classification. Crucially, the approach also provides enhanced transparency into the LLMs' decision-making, highlighting a practical pathway for Neuro-symbolic architectures to address LLM reasoning deficits."
url_dataset = ""
url_pdf = "https://arxiv.org/pdf/2510.09970?"
url_project = ""
url_slides = ""
url_video = ""
[[authors]]
  name = "Wang, Olivia Peiyu"
  is_member = false
[[authors]]
  name = "Bansal, Tashvi"
  is_member = false
[[authors]]
  name = "Bai, Ryan"
  is_member = false
[[authors]]
  name = "Chui, Emily M"
  is_member = false
[[authors]]
  name = "Gilpin, Leilani H"
  is_member = true
+++
